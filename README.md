
# YOLO ONNX Object Detection with FastAPI + Node-RED

---

## Overview

This project demonstrates how to **bridge FastAPI** (for high-speed inference) and **Node-RED** (for automation and visualization) to perform **real-time object detection** using a **YOLO ONNX model**.

Instead of running heavy ML inference inside Node-RED, which can be unstable or slow, we **offload inference to FastAPI**, which loads the YOLO model once and responds to requests efficiently.
Node-RED then orchestrates the flow, handles inputs, and visualizes results.

> ğŸ“˜ **Detailed step-by-step guide available here:**
> [**Bridging Node-RED and FastAPI for YOLO ONNX Object Detection**](https://medium.com/@abbirami.vnr/bridging-node-red-and-fastapi-for-yolo-onnx-object-detection-259151d39914)

---

## ğŸ§© Project Structure

```bash
C:\Users\User\.node-red\scripts\
â”‚
â”œâ”€â”€ predict_api.py         # FastAPI inference server
â”œâ”€â”€ yolo11n.onnx           # YOLO ONNX model file
â”œâ”€â”€ Cat.jpg                # Sample image
â”œâ”€â”€ node-red-flow.json     # Node-RED flow definition
â”œâ”€â”€ README.md              # Documentation
â””â”€â”€ venv/                  # Python virtual environment (optional)
````

-----

## âš™ï¸ Requirements

| Component | Version | Description |
| :--- | :--- | :--- |
| **Python** | $\ge 3.9$ | For running FastAPI and ONNX Runtime |
| **Node-RED** | $\ge 3.0$ | For flow-based orchestration |
| **FastAPI** | latest | REST API framework |
| **Uvicorn** | latest | ASGI server for FastAPI |
| **ONNX Runtime** | latest | Runs YOLO model on CPU/GPU |
| **OpenCV, Pillow, NumPy** | latest | Image preprocessing & handling |

### Install Dependencies:

```bash
pip install fastapi uvicorn numpy opencv-python onnxruntime pillow
```

-----

## Setup & Run

### 1ï¸âƒ£ Create and Activate Virtual Environment

```bash
python -m venv venv
venv\Scripts\activate     # Windows
# OR
source venv/bin/activate  # macOS/Linux
```

### 2ï¸âƒ£ Install Dependencies

```bash
pip install fastapi uvicorn numpy opencv-python onnxruntime pillow
```

### 3ï¸âƒ£ Place Your Model

Place your YOLO model file (e.g., `yolo11n.onnx`) inside:

```
C:\Users\User\.node-red\scripts\
```

### 4ï¸âƒ£ Run FastAPI Server

```bash
uvicorn predict_api:app --reload --host 127.0.0.1 --port 8000
```

### 5ï¸âƒ£ Test API Endpoint

Visit:

ğŸ‘‰ `http://127.0.0.1:8000/docs`

Upload an image under `/predict` â†’ **Execute**

Youâ€™ll receive a JSON response with detected object details.

### ğŸ“¸ Sample Response

```json
{
  "success": true,
  "best_detection": {
    "class": "cat",
    "confidence": 0.934,
    "box": [102.53, 69.40, 443.82, 603.23]
  },
  "inference_time_ms": 88.34
}
```

-----

## ğŸ”— Node-RED Integration

### ğŸ’¡ Import the Flow

1.  Open Node-RED Editor â†’ `http://127.0.0.1:1880`
2.  Click **Menu** â†’ **Import** â†’ **Clipboard**
3.  Paste the JSON from `node-red-flow.json`
4.  Click **Deploy**

### ğŸ”§ Flow Components

| Node | Function |
| :--- | :--- |
| **Inject** | Triggers workflow manually |
| **File In** | Reads local image |
| **Function** | Prepares `multipart/form-data` payload |
| **HTTP Request** | Sends `POST` to FastAPI `/predict` |
| **Debug** | Prints detection result |
| **Image Viewer** | Displays input image |

### HTTP Node Configuration

| Setting | Value |
| :--- | :--- |
| **Method** | `POST` |
| **URL** | `http://127.0.0.1:8000/predict` |
| **Headers** | `Content-Type: multipart/form-data` |

-----

## ğŸ§± Architecture

```mermaid
graph TD
    A[Node-RED Flow] -->|"Image Upload via HTTP POST"| B[FastAPI Server]
    B -->|"Runs YOLO ONNX Model"| C[ONNX Runtime]
    C -->|"Returns JSON Output"| A
    A -->|"Visualized in Dashboard"| D[Node-RED Dashboard]

```

### Component Breakdown

| Component | Role |
| :--- | :--- |
| **Node-RED** | Controls workflow, manages automation, visualizes results |
| **FastAPI** | Loads YOLO ONNX model, performs inference, returns JSON |
| **ONNX Runtime** | Executes the model efficiently on CPU/GPU |
| **Data Flow** | Image â†’ FastAPI â†’ JSON â†’ Node-RED dashboard |

### âš–ï¸ Why This Architecture Works

  * **Performance:** Model is loaded once in FastAPI, reused for all inferences.
  * **Stability:** Node-RED only handles lightweight HTTP requests.
  * **Scalability:** Can easily deploy FastAPI as a microservice.
  * **Portability:** Works on Windows, Linux, or Raspberry Pi.
  * **Clarity:** Clear separation between inference logic and automation logic.

-----

## ğŸ”® Next Steps

  * âœ… Add full YOLO postprocessing (Non-Max Suppression, multiple detections)
  * âœ… Integrate Node-RED Dashboard for real-time visualization
  * âœ… Package FastAPI as Docker container
  * âœ… Try GPU acceleration using `CUDAExecutionProvider`

-----

## ğŸ“š References

  * ğŸ§¾ **Medium Tutorial:** [Bridging Node-RED and FastAPI for YOLO ONNX Object Detection](https://medium.com/@abbirami.vnr/bridging-node-red-and-fastapi-for-yolo-onnx-object-detection-259151d39914)
  * âš™ï¸ [FastAPI Documentation](https://fastapi.tiangolo.com/)
  * ğŸ”´ [Node-RED Documentation](https://nodered.org/docs/)
  * ğŸ’¡ [ONNX Runtime](https://onnxruntime.ai/)

-----

## Author

ğŸ‘©â€ğŸ’» **Abbirami Jegan**

ğŸ”— [LinkedIn](https://www.linkedin.com/in/abbirami-jegan)

```
```
